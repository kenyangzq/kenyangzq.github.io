---
title: Beauty of Math 1
date: 2017-05-22 13:31:46
categories:
- Reading Note
- Beauty of Math
tags:
- Math

---

# 数学之美 笔记1
<br>

　　*Beauty of Math* is a book by Jun Wu, the former vice CEO of Tencent. It gives me a lot of inspiration so I chose to write down some of the reading note. Since the book is in Chinese, I felt much more convenient to write my note in Chinese and please forgive that. 

　　前一周有幸拜读了吴军老师当下的畅销书 --《智能时代》，感悟良多。根据书中指引，遂购买了吴军老师前几年颇具影响力的另一著作 -- 《数学之美》。作为数学专业的学生，阅读此书只觉得爱不释手，颇受启发，于是萌生记录阅读心得的想法。此篇写于去往南京的飞机上，于南京完成。

## 隐含马尔可夫模型
　　隐含马尔可夫模型（Hidden Markov Model）是书中的第五章，在前几张介绍了自然语言处理的基本思路后，自然而然的过渡到了这个简单高效的，解决自然语言处理难题的模型。

### 通信模型
　　书中首先介绍了基本的通信模型。雅各布森（Roman Jakobson）提出的通信六要素：发送者（信息源），信道，接受者，信息，上下文和编码。这一模型同样可被应用到自然语言的处理中，几乎所有的自然语言处理问题都可以等价成通信的解码问题。

　　给定观测信号$o_1, o_2, o_3...$，推测源信息$s_1, s_2, s_3...$可通过从所有信息中找到最可能产生观测信号的那一信息来完成。从概率角度说，就是求条件概率的最大值，即
$$
s_1,s_2,s_3... = Arg\,Max\;P(s_1,s_2,s_3...|o_1,o_2,o_3...)
$$
条件概率可通过贝叶斯公式变换为
$$
\frac
{P(o_1,o_2,o_3...|s_1,s_2,s_3...) \cdot P(s_1,s_2,s_3...)}{P(o_1,o_2,o_3...)}
$$

其中，因为 $o_1, o_2, o_3...$ 已经产生了，其概率是一个可以忽略的常数，所以剩下的只是

$$
P(o_1,o_2,o_3...|s_1,s_2,s_3...) \cdot P(s_1,s_2,s_3...)
$$

而这个公式完全可以用隐含马尔可夫模型来估计。

### 隐含马尔可夫模型

　　随机过程一般有两个维度的不确定性，一是对任意时间 $t$ ，其状态 $s$ 都是不确定的；二是一个状态 $s$ 受其他状态影响。而马尔可夫模型假设对任意状态 $s_t$ ，它只受前一个状态，即 $s_{t-1}$ 影响。这一假设被称为马尔可夫假设，而符合这一假设的随机过程被称为马尔可夫链。

　　计算某一状态 $m_i$ 到另一状态 $m_j$ 的转移概率可以通过数出 $m_i$ 出现的次数以及 $m_i$ 出现后 $m_j$ 出现的次数，后者除以前者便是其转移概率的估值。

　　隐含马尔可夫模型是上述的一个拓展：任一时刻 $t$ 的状态 $s_t$ 是不可见的，因此无法观测得到状态序列 $s_1,s_2,s_3...$ 来推测转移概率。但是，隐含马尔可夫模型在每一时刻 $t$ 都会输出一个符号 $o_t$ ，且 $o_t$ 只跟 $s_t$ 有关，所以我们可以就算出某个特定的状态序列 $s_1, s_2, s_3...$ 产生输出符号 $o_1, o_2, o_3...$ 的概率。

$$
P(o_1,o_2,o_3...|s_1,s_2,s_3...) = \prod P(s_t|s_{t-1}) \cdot P(o_t|s_t)
$$

至于如何找出上式的极值，可以利用维特比算法（Viterbi Algorithm)。

### 小结

　　隐含马尔可夫模型最初用于通信领域，是连接自然语言处理和通信的桥梁，同时也是机器学习的一大工具。

---

### 参考
-《数学之美》第二版第五章 -- 吴军

