<!DOCTYPE html>



  


<html class="theme-next pisces use-motion" lang="en">
<head>
  <meta charset="UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=edge" />
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"/>
<meta name="theme-color" content="#222">









<meta http-equiv="Cache-Control" content="no-transform" />
<meta http-equiv="Cache-Control" content="no-siteapp" />
















  
  
  <link href="/lib/fancybox/source/jquery.fancybox.css?v=2.1.5" rel="stylesheet" type="text/css" />







<link href="/lib/font-awesome/css/font-awesome.min.css?v=4.6.2" rel="stylesheet" type="text/css" />

<link href="/css/main.css?v=5.1.4" rel="stylesheet" type="text/css" />


  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png?v=5.1.4">


  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png?v=5.1.4">


  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png?v=5.1.4">


  <link rel="mask-icon" href="/images/logo.svg?v=5.1.4" color="#222">





  <meta name="keywords" content="Hexo, NexT" />










<meta name="description" content="Welcome to my hub">
<meta property="og:type" content="website">
<meta property="og:title" content="Runner">
<meta property="og:url" content="http://yoursite.com/index.html">
<meta property="og:site_name" content="Runner">
<meta property="og:description" content="Welcome to my hub">
<meta property="og:locale" content="en">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="Runner">
<meta name="twitter:description" content="Welcome to my hub">



<script type="text/javascript" id="hexo.configurations">
  var NexT = window.NexT || {};
  var CONFIG = {
    root: '/',
    scheme: 'Pisces',
    version: '5.1.4',
    sidebar: {"position":"left","display":"post","offset":12,"b2t":false,"scrollpercent":false,"onmobile":false},
    fancybox: true,
    tabs: true,
    motion: {"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}},
    duoshuo: {
      userId: '0',
      author: 'Author'
    },
    algolia: {
      applicationID: '',
      apiKey: '',
      indexName: '',
      hits: {"per_page":10},
      labels: {"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}
    }
  };
</script>



  <link rel="canonical" href="http://yoursite.com/"/>





  <title>Runner</title>
  








</head>

<body itemscope itemtype="http://schema.org/WebPage" lang="en">

  
  
    
  

  <div class="container sidebar-position-left 
  page-home">
    <div class="headband"></div>

    <header id="header" class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-wrapper">
  <div class="site-meta ">
    

    <div class="custom-logo-site-title">
      <a href="/"  class="brand" rel="start">
        <span class="logo-line-before"><i></i></span>
        <span class="site-title">Runner</span>
        <span class="logo-line-after"><i></i></span>
      </a>
    </div>
      
        <p class="site-subtitle">Hacking to the gate</p>
      
  </div>

  <div class="site-nav-toggle">
    <button>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
    </button>
  </div>
</div>

<nav class="site-nav">
  

  
    <ul id="menu" class="menu">
      
        
        <li class="menu-item menu-item-home">
          <a href="/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-home"></i> <br />
            
            Home
          </a>
        </li>
      
        
        <li class="menu-item menu-item-tags">
          <a href="/tags/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-tags"></i> <br />
            
            Tags
          </a>
        </li>
      
        
        <li class="menu-item menu-item-categories">
          <a href="/categories/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-th"></i> <br />
            
            Categories
          </a>
        </li>
      
        
        <li class="menu-item menu-item-archives">
          <a href="/archives/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-archive"></i> <br />
            
            Archives
          </a>
        </li>
      

      
    </ul>
  

  
</nav>



 </div>
    </header>

    <main id="main" class="main">
      <div class="main-inner">
        <div class="content-wrap">
          <div id="content" class="content">
            
  <section id="posts" class="posts-expand">
    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2018/01/27/RSA-Algorithm/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Ziqi Yang">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Runner">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2018/01/27/RSA-Algorithm/" itemprop="url">RSA Algorithm</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Posted on</span>
              
              <time title="Post created" itemprop="dateCreated datePublished" datetime="2018-01-27T23:26:24-06:00">
                2018-01-27
              </time>
            

            

            
          </span>

          
            <span class="post-category" >
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">In</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/Reading-Note/" itemprop="url" rel="index">
                    <span itemprop="name">Reading Note</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h1>RSA Algorithm</h1>
<p>RSA (Rivest–Shamir–Adleman) is one of the first public-key cryptosystems and is widely used for secure data transmission.</p>
<h2>How it works</h2>
<p>Thanks to my number theory class, I can appreciate and understand how the algorithm works.</p>
<h4>Before start</h4>
<p>As a convention, use Alice and Bob as example to explain the algorithm. Suppose Alice and Bob want to pass some information between them. Before they start, they choose a large number N which is the product of two prime number. For a simple example, let's use 61 and 53. Then N is 3233 in this case.</p>
<p>Generally people make N pretty large. The length of N in binary notation is the length of the key, and in general, people choose it to be 1024 or 2048 bits. In our case, $3233_{10} = 110010100001_{2}$, which is 12 bits.</p>
<p>Now all we have is $N = 3233$.</p>
<h4>Preparation</h4>
<p>Apply the Euler function $\phi$ on N. By definition, $\phi(N)$ equals the number of positive integers less than N that are coprime with N. And there is a general formula for $\phi$
$$
\phi(N) = N\prod_{\text{p | N}}(1-\frac{1}{p})
$$
The proof is pretty simple and straightforward. Since N is just a product of two prime p and q, we have $\phi(N) = (p-1)(q-1)$. We denote $\phi(N)$ as $r$.</p>
<p>Then Bob and Alice need to choose a number $e$ that's coprime with $r$. The reason behind this is to ensure a <em>modular multiplicative inverse</em> of $e$  modulo $r$ can be found.</p>
<p>By definition if b is a modular multiplicative inverse of a module r if
$$
a*b \equiv 1 ; mod(r)
$$
Mathematicians have developed systematic way to find multiplicative inverse and with computer, it only needs few lines of code.</p>
<p>Let's say we find the multiplicative inverse of $e$ modulo $r$ is $d$. Let's take $e=17  $ and $d=2753$ in our case. Now they have finished their preparation and are ready to pass message.</p>
<p>In addition, as a spoiler, $(N, e)$ will be the public key and $(N, d)$ will be the private key.</p>
<h4>Encryption</h4>
<p>Suppose Bob has a message $M$ to pass. He first translate it into a large integer $m$ using some scheme he and alice agrees on. Then he encrypts the message by
$$
c \equiv m^e ; mod(N)
$$
And send $c$ to Alice.</p>
<h4>Decryption</h4>
<p>After receive $c$, Alice recover the message by
$$
c^d \equiv (m^e)^d \equiv m ; mod(N)
$$
The proof is as follow:
$$
ed = k*r + 1
$$
for some integer k by the definition of modulo operation and the fact that $e$ and $d$ are multiplicative inverse of each other.</p>
<p>Then
$$
m^{ed} \equiv m*(m^{r})^k ; mod(N)
$$
Note that $r = \phi(N)$. According to Euler's Theorem:
$$
a^{\phi(N)} \equiv 1 ; mod(N)
$$
if $a$ and $N$ are coprime positive integer. This theorem is a generalization of Fermat's  Little Theorem, which is again built upon Wilson's Theorem. They can all be learned in a intro to number theory class.</p>
<p>Thus we have
$$
c^d = m^{ed} \equiv m * (m^r)^k \equiv m*(1)^k \equiv m ; mod(N)
$$
based on the properties of modulo operation.</p>
<p>Now Alice have the information Bob sent and all she need to do is to use the translation scheme to obtain the original message.</p>
<h2>To Break RSA</h2>
<p>Since the public key $(N, e)$ as it named, is public. An attacker only need to decompose the large number $N$ and obtain $\phi(N)$ to break the whole algorithm. However, such problem is well-known in mathematics as a very hard one for centuries. At least for now, no known method can guarantee to break the algorithm using fixed amount of resource.</p>
<h2>Last Thought</h2>
<p>I dig in RSA algorithm or the public-key cryptosystems since I am reading a book about block chain. Public-key cryptosystems is one of the building block in bitcoin, and I think they use SECP256k1 in particular. Other algorithms used include various kind of hashing, e.g. SHA-256, and some encoding / decoding algorithm.</p>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2017/11/29/Klondike-Solitaire-Web-App/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Ziqi Yang">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Runner">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2017/11/29/Klondike-Solitaire-Web-App/" itemprop="url">Klondike Solitaire Web App</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Posted on</span>
              
              <time title="Post created" itemprop="dateCreated datePublished" datetime="2017-11-29T22:13:56-06:00">
                2017-11-29
              </time>
            

            

            
          </span>

          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h1>Solitaire Web Application</h1>
<p>In 2017 fall semester, I implemented a React Card game Web Application. It's now deployed on <a href="http://34.230.72.14:8080" target="_blank" rel="noopener">AWS</a>. This app has many carefully designed features. I will introduce them one by one.</p>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2017/11/05/HDFS/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Ziqi Yang">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Runner">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2017/11/05/HDFS/" itemprop="url">HDFS</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Posted on</span>
              
              <time title="Post created" itemprop="dateCreated datePublished" datetime="2017-11-05T16:27:15-06:00">
                2017-11-05
              </time>
            

            

            
          </span>

          
            <span class="post-category" >
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">In</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/Study-Note/" itemprop="url" rel="index">
                    <span itemprop="name">Study Note</span>
                  </a>
                </span>

                
                
                  , 
                
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/Study-Note/Bigdata/" itemprop="url" rel="index">
                    <span itemprop="name">Bigdata</span>
                  </a>
                </span>

                
                
                  , 
                
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/Study-Note/Bigdata/Hadoop/" itemprop="url" rel="index">
                    <span itemprop="name">Hadoop</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h1>Hadoop Distributed File System</h1>
<p>Since HDFS is quite similar to GFS, to me, it's just an open-source GFS 2.0, I will not go into details on many subjects in this paper.</p>
<h2>Architecture</h2>
<h4>NameNode and DataNode</h4>
<p>​	In short, the architecture of HDFS is quite similar to GFS. They both adopt centralized structure, where  in HDFS the NameNode is the master in GFS and DataNodes are chunkservers. Just like in GFS, NameNode handles the metadata. It maintains the namespace tree and mapping of files blocks to DataNodes. Typically, each cluster has a NameNode and lots of DataNode.</p>
<p>NameNode can run as either <em>CheckpointNode</em> or <em>BackupNode</em>.</p>
<p>​	HDFS keeps the entire namespace in RAM. It also uses checkpoint and journal to provide fault recovery. Note, the location of DataNode is not stored in the checkpoint.</p>
<p>​	The DataNode also uses checksum to prevent data lost. It stores two file for each block replica, one for data and one for metadata including checksum and <em>generation stamp</em>. Version number is used to remove stale data. Namespace ID is used to decide whether DataNode belongs to a cluster.</p>
<p>​	During normal operation, DataNode sends <em>heartbeats</em> to the NameNode. Heartbeats carry information of the DataNode, like storage capacity, number of data transfers in progress. The NameNode replies to heartbeats to send instructions, including:</p>
<ul>
<li>replicate blocks to other nodes</li>
<li>remove local block replicas</li>
<li>re-register or shut down the node</li>
<li>send an immediate block report, (which is a summary of a block's information)</li>
</ul>
<h4>Image and Journal</h4>
<p>The namespace <em>image</em> is the file system metadata that describes the organization of application data as directories and files. A persistent record of the image written to disk is called a <em>checkpoint</em>.</p>
<p>The journal is in fact a <em>write-ahead log</em>, which is a technique widely applied in modern database. For each transaction, the change is recorded in the journal, and the journal file is flushed and synched before the change is committed.</p>
<p>This design has a drawback, since NameNode is a multithread system, saving a transaction to the disk may become a bottleneck as all other thread need to wait. The HDFS optimize this by batching transactions to save.</p>
<h2>File I/O Operation</h2>
<h4>File Read &amp; Write</h4>
<p>After a file is closed, the bytes written cannot be altered or removed except that new data can be appended to the end. HDFS also implements a single-writer, multiple reader model. It uses <em>lease</em> to grant permission to client, just as GFS, which means write with concurrent read is supported as well.</p>
<p>When writing files, push sequence of packets on a <em>pipeline</em> to write to blocks that stores the file and its replicas. Need to setup and close the pipeline before and after write. Note, in the figure, a <em>hflush</em> operation is conducted right after packet 2 is sent. It will force the client to wait for the confirm information of packet 2 received before sending packet 3.</p>
<p>&lt;img src=&quot;../images/Papers/HDFS-datapipeline.png&quot; width=&quot;400&quot;&gt;</p>
<h4>Block Placement and Others</h4>
<p>As in GFS, HDFS tends to split replicas on different machines and also different racks. The default HDFS replica placement policy can be summa- rized as follows:</p>
<ol>
<li>No Datanode contains more than one replica of any block.</li>
<li>No rack contains more than two replicas of the same block, provided there are sufficient racks on the cluster.</li>
</ol>
<p>Other functionalities provided by HDFS include balancer, a tool to balance disk usage on cluster, and block scanner, which periodically scans a block's replicas and verifies the checksum.</p>
<p><em>In my thought, some of the mechanism in HDFS are just grouping functions in GFS into small units and manage them separately.</em></p>
<h2>Conclusion</h2>
<p>The rest of the paper is practice experience, future works and acknowledgement. In short, HDFS is a powerful distributed system, which is like an open-source,  upgraded GFS.</p>
<p>One final thing to note, the major drawback of having many namespaces is the cost of managing them. I guess that's an important reason for YARN to show up.</p>
<h2>Reference</h2>
<p>[1] K V Shvachko, H Kuang, S Radia, R Chansler, Yahoo!. 2010. <em>The Hadoop Distributed File System</em></p>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2017/10/29/hello-world/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Ziqi Yang">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Runner">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2017/10/29/hello-world/" itemprop="url">Hello World</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Posted on</span>
              
              <time title="Post created" itemprop="dateCreated datePublished" datetime="2017-10-29T20:15:01-05:00">
                2017-10-29
              </time>
            

            

            
          </span>

          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <p>Welcome to <a href="https://hexo.io/" target="_blank" rel="noopener">Hexo</a>! This is your very first post. Check <a href="https://hexo.io/docs/" target="_blank" rel="noopener">documentation</a> for more info. If you get any problems when using Hexo, you can find the answer in <a href="https://hexo.io/docs/troubleshooting.html" target="_blank" rel="noopener">troubleshooting</a> or you can ask me on <a href="https://github.com/hexojs/hexo/issues" target="_blank" rel="noopener">GitHub</a>.</p>
<h2>Quick Start</h2>
<h3>Create a new post</h3>
<p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo new <span class="string">"My New Post"</span></span><br></pre></td></tr></table></figure></p>
<p>More info: <a href="https://hexo.io/docs/writing.html" target="_blank" rel="noopener">Writing</a></p>
<h3>Run server</h3>
<p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo server</span><br></pre></td></tr></table></figure></p>
<p>More info: <a href="https://hexo.io/docs/server.html" target="_blank" rel="noopener">Server</a></p>
<h3>Generate static files</h3>
<p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo generate</span><br></pre></td></tr></table></figure></p>
<p>More info: <a href="https://hexo.io/docs/generating.html" target="_blank" rel="noopener">Generating</a></p>
<h3>Deploy to remote sites</h3>
<p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo deploy</span><br></pre></td></tr></table></figure></p>
<p>More info: <a href="https://hexo.io/docs/deployment.html" target="_blank" rel="noopener">Deployment</a></p>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2017/10/29/MapReduce-2/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Ziqi Yang">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Runner">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2017/10/29/MapReduce-2/" itemprop="url">MapReduce-2</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Posted on</span>
              
              <time title="Post created" itemprop="dateCreated datePublished" datetime="2017-10-29T12:38:34-05:00">
                2017-10-29
              </time>
            

            

            
          </span>

          
            <span class="post-category" >
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">In</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/Study-Note/" itemprop="url" rel="index">
                    <span itemprop="name">Study Note</span>
                  </a>
                </span>

                
                
                  , 
                
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/Study-Note/Bigdata/" itemprop="url" rel="index">
                    <span itemprop="name">Bigdata</span>
                  </a>
                </span>

                
                
                  , 
                
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/Study-Note/Bigdata/Hadoop/" itemprop="url" rel="index">
                    <span itemprop="name">Hadoop</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h1>Second Look at MapReduce</h1>
<p>Early I have written a very simple post about the idea of MapReduce. It was in fact part of the my lecture note in the Big Data course. Recently I re-read the paper, <em>MapReduce: simplified data processing on large clusters</em> [1], and I want to add some note to this topic. I will not follow the order of the paper and only write down some of the things that stands out, including my own thought and other related topics.</p>
<h2>Programming Model</h2>
<p>The interface is pretty simple: typically MapReduce is a imported library, e.g. <a href="https://github.com/Yelp/mrjob" target="_blank" rel="noopener">mrjob</a>; user only needs to define the map and reduce function and pass them to the library to run.</p>
<h4>Execution Overview</h4>
<p>As discussed in paper, input data is first partitioned into <em>M</em> splits for Map node; later on there will be <em>R</em> worker node for Reduce operation. Typically, number <em>M</em> and <em>R</em> are much larger than the number of machines.</p>
<p>Each worker executes the map function user defined. And results are written to local disk periodically.  The master is responsible for a schedule plan to reduce transmission need. Typically, it will try to put reduce node near map node. In this way, most input data is read locally and consumes no nework bandwidth.</p>
<p><strong>Note</strong>:</p>
<ol>
<li>One reason that Spark is much faster is that intermediate results are written to local disk, and Reduce nodes have to read from disk while Spark stores all the RDDs in memory.</li>
<li>Reduce nodes cannot start until all Map nodes finish. There is a Barrier between these two nodes.</li>
</ol>
<h4>A Confusion</h4>
<p>The paper indicates that after all the intermediate keys are received, they are sorted on the reduce node so that all occurance of the same key are grouped together. I don't quite unerstand how they achieve this. To me, it will make more sense for master to handle this. After all the intermediate results are read, master sorts them, possibly use external sort as data volume is too large to fit in memory. Then the sorted result is fed to Reduce nodes. But in this way the network bandwidth will be a restriction.</p>
<p><em>After discussion with a professor, I realized that the shuffle part between map and reduce is not covered in this paper. In fact, after mapper writes the data to local disk, it sorted the data. And the master shuffle the sorted results from each worker and then schedule the whole reduce task. This explains why there has to be a barrier between map and reduce.</em></p>
<h2>Fault Tolerance</h2>
<h4>Worker</h4>
<p>The MapReduce library kind of supports a strong fault tolerance on worker node. But compared to Spark, it's too inefficient.</p>
<p>On map task, if one fails, this task has to be re-executed in its entirety as the intermediate results are stored on local disks. But for reduce task, since the result is outputed to some global file system, (GFS with no doubt at that time, 2004), there is no need to re-start the whole reduce task.</p>
<h4>Master</h4>
<p>In the paper, they mention that they can use checkpoint as in GFS to maintain the master status. However, due to the small chance of failure, they decided to just abort the task.</p>
<p><em>I think they can also adopt the idea of shadow master from GFS. The primal master can record append the status and location of worker tasks to a chunk in GFS. When the master failed, the shadow master can continue from the chunk and handle the rest.</em></p>
<p>Just some naive thoughts.</p>
<h2>Others</h2>
<p>The paper also mentioned how they take advantages of location information to better schedule the task, the task granularity. In addition, they handle straggler by scheduling multiple backup tasks.</p>
<h4>Combiner</h4>
<p>In some cases when repetition in keys are frequent and reduce operation is <em>communative</em> and <em>associative</em>, MapReduce allows user to add a <em>Combiner</em> function to optimize.</p>
<p>In my view, it's the same as a pre-reduce on Map operation.</p>
<h2>Conclusion</h2>
<p>In short, MapReduce is a very powerful programming model which pave the way for modern big data processing techniques.</p>
<h2>Reference</h2>
<p>[1] Dean J, Ghemawat S. 2008. MapReduce: Simplified data processing on large clusters. Commun ACM 51: 107–113.</p>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2017/10/28/Pyspark-in-Jupyter-Notebook-with-SSH-Forward-Porting-on-Local-VM/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Ziqi Yang">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Runner">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2017/10/28/Pyspark-in-Jupyter-Notebook-with-SSH-Forward-Porting-on-Local-VM/" itemprop="url">Pyspark in Jupyter Notebook with SSH Forward Porting on Local VM</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Posted on</span>
              
              <time title="Post created" itemprop="dateCreated datePublished" datetime="2017-10-28T16:55:19-05:00">
                2017-10-28
              </time>
            

            

            
          </span>

          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h1>Pyspark in Jupyter Notebook with SSH Forward Porting on Local VM</h1>
<p>This is a note I used to setup Pyspark environment on local VM with vagrant.</p>
<h3>Step One — Spawn Local VM</h3>
<p>Vagrant up a local virtual machine. There is only one line in VagrantFile that needs to change. Comment back the following line. Note, the guest port should be 8888 as the defualt port for Jupyter notebook is 8888. The host port can be whatever you like.</p>
<p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">config.vm.network &quot;forwarded_port&quot;, guest: 8888, host: 8888</span><br></pre></td></tr></table></figure></p>
<p>It's recommended that you set up a shared folder as always. We need to use it to pass the Spark.tgz file into VM. The corresponding line in VagrantFile is:</p>
<p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">config.vm.synced_folder &quot;./ShareFile&quot;, &quot;/vagrant_data&quot;</span><br></pre></td></tr></table></figure></p>
<p>where <code>ShareFile</code> is a folder I created on the same directory as VagrantFile. You can name and put your sharefolder in whatever manner you like.</p>
<h3>Step Two — Install Needed Packages</h3>
<p>Use <code>vagrant ssh</code> to shell into your local VM. Install packages using the following command:</p>
<p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">sudo apt-get update</span><br><span class="line">sudo apt-get install -y python3</span><br><span class="line">sudo apt-get install -y python3-pip</span><br><span class="line">pip3 install py4j</span><br><span class="line">pip3 install jupyter</span><br><span class="line">sudo apt-get install -y default-jre</span><br><span class="line">sudo apt-get install -y scala</span><br></pre></td></tr></table></figure></p>
<p>These commands install python3, pip3, py4j,  Jupyter notebook, Java and Scala respectively. Java and Scala are needed because Spark is written in Scala and Scala is written in Java.</p>
<h3>Step Three — Download Spark Latest Version</h3>
<p>Download Spark lateset version for ubuntu &lt;a href=&quot;https://spark.apache.org/downloads.html&quot;&gt;here&lt;/a&gt;. I downloaded <a href="https://www.apache.org/dyn/closer.lua/spark/spark-2.2.0/spark-2.2.0-bin-hadoop2.7.tgz" target="_blank" rel="noopener">spark-2.2.0-bin-hadoop2.7.tgz</a>. It should be roughly 200 MB. After downloading, put it in the shared folder.</p>
<p>In the local vm, use <code>mv</code> to move the tgz file to the <code>/home/ubuntu</code> directory, i.e. the root directory. Type the following command to unpack the file.</p>
<p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo tar -zxvf spark-2.2.0-bin-hadoop2.7.tgz</span><br></pre></td></tr></table></figure></p>
<h3>Step Four — Configure the Pyspark Environment</h3>
<p>At the root directory of the local VM, use whatever text editor you prefer to open the <code>.bashrc</code> file. Copy and paste the following line at the end of the file.</p>
<p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">export SPARK_HOME=&apos;/home/ubuntu/spark-2.2.0-bin-hadoop2.7&apos;</span><br><span class="line">export PATH=$SPARK_HOME:$PATH</span><br><span class="line">export PYTHONPATH=$SPARK_HOME/python:$PYTHONPATH</span><br><span class="line"></span><br><span class="line">export PYSPARK_DRIVER_PYTHON=jupyter</span><br><span class="line">export PYSPARK_DRIVER_PYTHON_OPTS=&apos;notebook&apos;</span><br></pre></td></tr></table></figure></p>
<p>These lines specify the needed path to find the pyspark module in Jupyter notebook. After editting, type this command in the same directory:</p>
<p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">source ./bashrc</span><br></pre></td></tr></table></figure></p>
<p>Finally, change the permission of the Spark files.</p>
<p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">suco chmod 777 spark-2.2.0-bin-hadoop2.7.tgz</span><br><span class="line">cd spark-2.2.0-bin-hadoop2.7.tgz/</span><br><span class="line">sudo chmod 777 python </span><br><span class="line">cd python/</span><br><span class="line">sudo chmod 777 pyspark</span><br></pre></td></tr></table></figure></p>
<p>These commands will give the user privileges to access the pyspark module.</p>
<h3>Step Five — Restart the VM and Check</h3>
<p>Now restart the virtual machine. You can exit it and use <code>vagrant reload</code> to do so.</p>
<p>After restart, shell into the local vm and under whatever folder, type the following command to start the jupyter notebook:</p>
<p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">jupyter notebook --ip=0.0.0.0</span><br></pre></td></tr></table></figure></p>
<p><strong>Note: the —ip argument is needed to enable forward porting!!</strong></p>
<p>Now you can open a browser on the host machine. Type in <code>https://localhost:8888</code> or whatever host port you have chosen. You should be able to access the Jupyter Notebook in the local vm.</p>
<p>Then in the notebook, try the following command:</p>
<p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">import pyspark</span><br></pre></td></tr></table></figure></p>
<p>This should not give any output.</p>
<p>If no error is generated, then congratulation, you have successfully setup !</p>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2017/10/19/GFS-2/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Ziqi Yang">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Runner">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2017/10/19/GFS-2/" itemprop="url">GFS-2</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Posted on</span>
              
              <time title="Post created" itemprop="dateCreated datePublished" datetime="2017-10-19T20:13:34-05:00">
                2017-10-19
              </time>
            

            

            
          </span>

          
            <span class="post-category" >
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">In</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/Study-Note/" itemprop="url" rel="index">
                    <span itemprop="name">Study Note</span>
                  </a>
                </span>

                
                
                  , 
                
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/Study-Note/Bigdata/" itemprop="url" rel="index">
                    <span itemprop="name">Bigdata</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h1>Google File System Note 2</h1>
<p>Continue from note 1. This note is also based on the Google File System paper [1].</p>
<h2>Master Operations</h2>
<p>The master execute all the namespace operations. It makes placement decisions, creates new chunks and hence replicas, and coordinates various system-wide activities to keep chunks fully replicated, to balance load across all the chunkservers, and to reclaim unused storage.</p>
<h4>Namespace Management and Locking</h4>
<p>To allow multiple master operation running concurrently, the master uses locks over regions of the namespace to ensure proper serialization.</p>
<p>GFS logically represents its namespace as a lookup table mapping full pathnames to metadata. Each node in the namespace tree, no matter a file name or a directory name, has an associated read-write lock.</p>
<p>Each master operation acquires a set of locks before it runs. It will acquire read-locks on all the related directory names, as /d1, /d1/d2, ..., /d1/d2/…/dn, and either a read or write lock on the full path name /d1/d2/.../dn/leaf. Note that the leaf can be a directory or a file.</p>
<p>The read / write locks in GFS are the same as locks in other file system. Two things to note:</p>
<ol>
<li>File creation does not require a write lock on the parent directory because there is no “directory” to be protected. A read lock is enough.</li>
<li>Locks are acquired in a consistent total order to prevent deadlock</li>
</ol>
<p>One nice property of this locking scheme is that it allows concurrent mutations in the same directory.</p>
<h4>Replica Placement</h4>
<p>The chunk replica placement policy serves two purposes: maximize data reliability and availability, and maximize net- work bandwidth utilization.</p>
<p>GFS spreads chunk replicas across not only  machines but also racks to prevent from rack damage or offline. This also enables read for a chunk to exploit the aggregate bandwidth of multiple racks</p>
<h4>Garbage Collection</h4>
<p>When a file is deleted, GFS reclaim the physical storage azily during regular garbage collection at both the file and chunk levels.</p>
<h5>Mechanism</h5>
<p>When a file is deleted, the operation is logged just liked others. However, the file is just renamed to a hidden name that includes the deletion timestamp. The file is actually removed during the master’s regular scan of the file system namespace after it exists for more than three days (configurable). When the hidden file is removed from the namespace, its in- memory metadata is erased.</p>
<p>This mechanism provide efficient way to undelete file.</p>
<h4>Stale Replica Detection</h4>
<p>For each chunk, the master maintains a chunk version number to distinguish between up-to-date and stale replicas. Whenever the master grants a new lease on a chunk, it increases the chunk version number and informs the up-to-date replicas.</p>
<p>Whenever chunk version number conflicts, always assume that the largest is up-to-date, even when the master's record is not the largest.</p>
<h2>Fault Tolerace and Diagnosis</h2>
<p>One of the greatest challenges in designing the system is dealing with frequent component failures.</p>
<h4>High Availability</h4>
<p>Two simple yet effective strategies: fast recovery and replication.</p>
<h5>Fast Recovery</h5>
<p>GFS does not distinguish between normal and abnormal termination. Both the master and the chunkserver are designed to restore their state and start in seconds.</p>
<h5>Replication</h5>
<p>For chunks, each chunk is replicated on multiple chunkservers on different racks.</p>
<p>For master, its operation log and checkpoints are replicated on multiple machines. A mutation to the state is considered committed only after its log record has been flushed to disk locally and on all master replicas.</p>
<h5>Shadow Master</h5>
<p>GFS also support &quot;<em>shadow masters</em>&quot;. They provide read-only access to the file system when the primary master is down. These shadows may lag the primary slightly, but they enhance read availability for files that are not being actively mutated or applications that do not mind getting slightly stale results.</p>
<p>To keep informed, a shadow master reads a replica of the growing operation log and applies the same sequence of changes to its data structures exactly as the primary does. It depends on the primary master only for replica location updates resulting from the primary’s decisions to create and delete replicas.</p>
<h4>Data Integrity</h4>
<p>Each chunkserver uses checksumming to detect corruption of stored data. As discussed in the first note, the semantics of GFS mutations, in particular atomic record append, does not guar- antee identical replicas.</p>
<p>The paper does not discuss the <strong>checksum</strong> GFS uses. One typical and simple checksum algorithm is parity byte or parity word,  which breaks the data into &quot;words&quot; with a fixed number <em>n</em> of bits, and then computes the exclusive or (XOR) of all those words. The result is appended to the message as an extra word. To check the integrity of a message, the receiver computes the exclusive or of all its words, including the checksum; if the result is not a word with <em>n</em> zeros, the receiver knows a transmission error occurred. Detailed discussion of checksum can be found on <a href="https://en.wikipedia.org/wiki/Checksum" target="_blank" rel="noopener">Wikipedia</a>.</p>
<h2>Measurements &amp; Related Works</h2>
<p>I will skip these parts as that's pretty outdated (2003) and they are also not the thing I want to learn from this paper.</p>
<h2>Conclusion</h2>
<p>In GFS, they treat component failures as the norm rather than the exception, optimize for huge files that are mostly appended to (perhaps concurrently) and then read (usually sequentially), and both extend and relax the standard file system interface to improve the overall system.</p>
<p>The system provides fault tolerance by constant moni- toring, replicating crucial data, and fast and automatic recovery. Additionally, we use checksumming to detect data corruption at the disk or IDE subsystem level.</p>
<p>GFS achieves high aggregate throughput by separating file system control, which passes through the master, from data transfer, which passes directly between chunkservers and clients. Master involve- ment in common operations is minimized by a large chunk size and by chunk leases.</p>
<h2>Reference</h2>
<ol>
<li>Ghemwat, Sanjay, Howard Gobioff, and Shun-Tak Leung (Google). <em>“The Google</em>
<em>File System.”</em> Symposium on Operating Systems Principles (SOSP) ’03,
Association of Computing Machinery. Published 2003.</li>
</ol>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2017/10/16/GFS-1/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Ziqi Yang">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Runner">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2017/10/16/GFS-1/" itemprop="url">GFS-1</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Posted on</span>
              
              <time title="Post created" itemprop="dateCreated datePublished" datetime="2017-10-16T21:19:53-05:00">
                2017-10-16
              </time>
            

            

            
          </span>

          
            <span class="post-category" >
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">In</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/Study-Note/" itemprop="url" rel="index">
                    <span itemprop="name">Study Note</span>
                  </a>
                </span>

                
                
                  , 
                
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/Study-Note/Bigdata/" itemprop="url" rel="index">
                    <span itemprop="name">Bigdata</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h1>Google File System Note 1</h1>
<p>During my lesure time, I plan to review some of my big data paper. I will try to write study note for some of the paper that I find important or interesting. This is the note for the first half of the famous Google File System paper [1].</p>
<h2>Introduction</h2>
<p>There are several traindtional choices that the authors decided to reexamined and they wanted to  explore radically different points in the design space.</p>
<ol>
<li>Component failures are the norm rather than the exception.</li>
</ol>
<p>There are all sorts of possible failures. Constant monitoring, error detection, fault tolerance and automatic recovery must be integral to the system.</p>
<ol start="2">
<li>Files are huge.</li>
<li>Most files are mutated by appending new data rather than overwriting existing data.</li>
<li>Co-designing the applications and the file system API benefits the overall system by increasing flexibility.</li>
</ol>
<h2>Design Overview</h2>
<h4>Assumptions</h4>
<p>They have listed quite a few assumptions. Of those, I extract a few that catch my attention</p>
<ul>
<li>There are typically two types of reads:
<ul>
<li>Large streaming reads</li>
<li>Small random reads
<ul>
<li>Performance-conscious applications often batch and sort their small reads.</li>
</ul>
</li>
</ul>
</li>
<li>The system must efficiently implement well-defined semantics for mutiple clients that concurrently append to the same files. (Spoiler: I believe they use <em>record appen</em>d to handle this problem)</li>
<li>High sustained bandwidth is more important than low latency.</li>
</ul>
<h4>Interface</h4>
<p>GFS supports the usual <strong>CRUD</strong> operations, where they name them as <em>create, delete, open, write, close, and read</em>. Moreover, GFS has <em>snapshot</em> and <em>record</em> <em>append</em> operations. They are discussed later.</p>
<h4>Architecture</h4>
<p>A GFS cluster consists of a single master and multiple chunkservers. The architecture is shown below.</p>
<p>&lt;img src=&quot;/images/Papers/GFS-architecture.png&quot;&gt;</p>
<p>Files are divided into fixed-size <em>chunks</em>, typically 64 MB. Each chunk is identified by an immutable and globally unique 64 bit chunk handle assigned by the master at the time of chunk creation. For reliability, each chunk is replicated on multiple chunkservers.</p>
<p>The master maintains all the metadata. It periodically communicates with each chunkserver in <em>HeartBeat</em> messages to give instructions and collect its state.</p>
<p>Clients interact with the master for metadata operations, but all data-bearing communication goes directly to the chunkservers.</p>
<p>Neither the client nor the chunkserver caches file data. Clients do cahce metadata, however. These metadata are used to locate chunkservers and are sent from the master.</p>
<h4>Single Master</h4>
<p>Since there is only one master, GFS must minimize its involvement in reads and writes so that it won't become a bottleneck. The client get information of chunkserver from master and directly interact with those servers.</p>
<p>For example, to perform a simple read, the client first translates the file name and byte offset into a chunk index with the file according to the fixed size of chunks. It sends the master with this information and gets back the corresponding chunk handle and its replicas' locations. Then the client contacts directly with chunkserver for the subsequent operations, and master is not involved.</p>
<h4>Chunk Size</h4>
<p>The authors suggested 64 MB chunk size. GFS uses lazy space allocation to avoid wasting space due to internal fragmentation.</p>
<p>There are several advantages with a big chunk size:</p>
<ol>
<li>It reduces clients' need to interact with the master as reads and writes on same chunk only need one initail request.</li>
<li>It reduces network overhead by keeping a persistent TCP connection.</li>
<li>It reduces the size of metadata stored on master.</li>
</ol>
<p>There is also a disadvantage:</p>
<ul>
<li>Small files on only one chunk may turn it into a hot spot when many clients are accessing it at the same time.</li>
</ul>
<h4>Metadata</h4>
<p>The master stores three major types of metadata in its memory: the file and chunk namespaces, the mapping from files to chunks, and the locations of each chunk’s replicas.	The first two types are also kept persistent by logging mutations to an operation log stored on the master’s local disk and replicated on remote machines.</p>
<h5>In-Memory Data Structure</h5>
<p>Master operations are fast as metadata are in memory. Furthermore, the master periodically 	scan through its entire state in the background.</p>
<p>One may concern that the system is limited by the memory size. In fact this is not a serious limit as one chunk only needs less than 64 byte to store.</p>
<h5>Chunk Locations</h5>
<p>The master does not keep a persistent record of which chunkservers have a replica of a given chunk. It simply polls chunkservers for that information at startup.</p>
<h5>Operation Log</h5>
<p>This is the only persistent record of metadata on GFS. It also servers as a logical time line that defines the order of concurrent operations. It's replicated on multiple remote machines and respond to a client operation only after flushing the corresponding log record to disk both locally and remotely.</p>
<p>The master recovers its file system state by replaying the operation log. To keep the log small, the master checkpoins its state whenever the log grows beyond a threshold. The checkpoint is a compact B-tree like form that can be directly mapped into memory.</p>
<h4>Consistency Model</h4>
<p>GFS has a relaxed consistency model.</p>
<h5>Guarantees by GFS</h5>
<p>Two definitions:</p>
<ul>
<li>A file region is consistent if all clients will always see the same data, regardless of which replicas they read from.
<ul>
<li>A region is defined after a file data mutation if it is consistent and clients will see what the mutation writes in its entirety.</li>
</ul>
</li>
</ul>
<p>After a sequence of successful mutations, the mutated file region is guaranteed to be defined and contain the data written by the last mutation.</p>
<h2>System Interactions</h2>
<p>The GFS system is designed to minimize the master's involvement in all operations.</p>
<h4>Lease and Mutations Orders</h4>
<p>A mutation is an operation that changes the contents or metadata of a chunk such as a write or an append operation. GFS uses <strong>lease</strong> to maintain a consistent mutation order across all replicas.</p>
<p>The master grants a chunk lease to one of the replicas, which we call the <em>primary</em>. The primary picks a serial order for all mutations to the chunk. All replicas follow this order when applying mutations.</p>
<p>​			&lt;img src=&quot;/images/Papers/GFS-dataflow.png&quot; width=&quot;400&quot; class=&quot;center&quot;&gt;</p>
<p>The figure above shows the detailed order of write control and data flow.</p>
<h4>Data Flow</h4>
<p>To fully utilize each machine’s network bandwidth, the data is pushed linearly along a chain of chunkservers. Each machine forwards the data to the “closest” machine in the network topology that has not received it. Once a chunkserver receives some data, it starts forwarding immediately.</p>
<h4>Atomic Record Appends</h4>
<p>In a record append operation, the client only specifies the data. GFS will append to the file <em>at least once atomically</em> at an offset GFS choosing and returns that offset to the client.</p>
<p>When record append, need to check whether the chunk will exceed the maximum size.</p>
<ul>
<li>If so, insert padding to the chunk and its replicas. Then informs the client that the operation should be retried on next chunk. (RA is restricted to be at most one-fourth of the chunk size.)</li>
<li>If fits inside the chunk, the primary appends the data, informs the secondaries to do the same and finally replies success to the client.</li>
</ul>
<p>GFS does not guarantee that all replicas are bytewise identical. It only guarantees that the data is written at least once as an atomic unit.</p>
<h4>Snapshot</h4>
<p>The snapshot operation makes a copy of a file or a directory tree almost instantaneously. Uses <strong>copy-on-write</strong> techniques to implement.</p>
<p>To perform snapshot:</p>
<ol>
<li>Revok all the leases on the chunks in which files are about to snapshot.</li>
<li>Then master logs the operation to the log and duplicate the metadata for the source file or directory tree.</li>
<li>When client write to the snapshot, copy all the replicas locally by creating new chunks on the same chunkserver.</li>
</ol>
<h2>Reference</h2>
<ol>
<li>Ghemwat, Sanjay, Howard Gobioff, and Shun-Tak Leung (Google). <em>“The Google</em>
<em>File System.”</em> Symposium on Operating Systems Principles (SOSP) ’03,
Association of Computing Machinery. Published 2003.</li>
</ol>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2017/10/04/Offer-From-Microsoft/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Ziqi Yang">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Runner">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2017/10/04/Offer-From-Microsoft/" itemprop="url">Offer From Microsoft</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Posted on</span>
              
              <time title="Post created" itemprop="dateCreated datePublished" datetime="2017-10-04T21:23:14-05:00">
                2017-10-04
              </time>
            

            

            
          </span>

          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h1>Offer From Microsoft</h1>
<h2>Preparation</h2>
<p>This summer, while doing research with Professor Schumaker, I got this idea: why not find an internship at big Tech Company right before my grad school?</p>
<p>So I start to prepare in August. I do have applied to Google and Microsoft for internship last year, but I did that too late. So it turns out that I got an open offer from Google but did not match any team. For Microsoft, I passed the first round but they did not have enough headcount to even schedule a final round for me.</p>
<p>With some experience, I made a plan for applying to Tech Companies. The most important thing is the problem solving skill, namely to solve algorithm problem on white board. I use Leetcode, a free website, and the famous <em>Cracking the Code Interview</em> to prepare.</p>
<p>I got email from Microsoft at mid August and we schedule an onsite interview in Early October. Before that all I did is actually just going over all the courses in CS department that I have took and to keep practicing.</p>
<h3>Interview</h3>
<p>Last Monday, I flew all the way from Nashville to Seattle, Microsoft Campus at Redmond. The interview is scheduled at 7:30 a.m and I have to get up at about 6:30 as I stayed in a hotel 20 mins away from the building by taxi.</p>
<p>The interview consists of 4 rounds, each around 45 mins, from 8:00 to 12:00. Due to confidentiality concerns, I cannot disclose any problems that I got. But the overall process is pretty smooth. The interviewers are pretty nice, most of them have been working for Microsoft for more than 10 years. The group I am interviewing with are Azure group and the intern and fulltime offer that I got later are all for this group.</p>
<p>After the interview, all the interviewees are brought to the Microsoft campus dining hall, called Commons, for lunch. I made accquaintance with some of the interviewees from all over the U.S. Though the food is not that tasty, I did have a good time there.</p>
<p>After that, we were dismissed and I went directly back to my hotel since I really didn't sleep well the night before.</p>
<h3>Offer</h3>
<p>Two days ago, I finally got my offer as an intern. I used the word 'finally' because generally they made decisions within few days. The reason I got a delay is hilarious. It turns out that I have a pretty messy handwriting and they kept a wrong phone number in the system. My recruiter has been calling me since last Wednesday, when they have already made a decision.</p>
<p>Just like the good old Chinese phrase, &quot;好事多磨&quot;, which means good fortune may come after some amount of troubles. Since I am graduating next year right before my intern starts, I have no idea how and where to get a kind of VISA to legally work in U.S. So I called my recruiter and tried to get some advice.</p>
<p>That's when I got the news that since I am eligible for a fulltime position, <strong>they decide to just give me a fulltime offer</strong>. If I preferred to go to grad school later, I can decline it and rearrange it into an intern!</p>
<p>This is amazing and totally surprising!! Later one of my friends who work at Facebook told me, it may due to my good performance at the interview that Microsoft thought I am qualified for a direct fulltime offer. Now my faith for graduate school is shaken. Some friends suggested me to work for a few years first and then go for grad. Since I am undergoing this tedious and consuming graduate school application process, I really don't know what's the right choise.</p>
<p>Hopefully when I look back at this post next year, I have already made a promising decision and won't regret for it in the further future. We will see.</p>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2017/09/23/Manually-Deploy-Cloud-Architecture/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Ziqi Yang">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Runner">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2017/09/23/Manually-Deploy-Cloud-Architecture/" itemprop="url">Manually Deploy Cloud Architecture</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Posted on</span>
              
              <time title="Post created" itemprop="dateCreated datePublished" datetime="2017-09-23T13:31:01-05:00">
                2017-09-23
              </time>
            

            

            
          </span>

          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h1>Manually Deploy Cloud Architecture</h1>
<p>This is a step by step tutorial of how to setup LAMP stack on two virtual machines on OpenStack cloud infrastructure. After configuration, we want to deploy the &lt;a href=&quot;https://github.com/Anirban2404/phpMySQLapp.git&quot;&gt;phpMySQLapp&lt;/a&gt; on our servers. The two virtuall machines will be functioned as web server and database server respectively.</p>
<p>Creation and configuration of virtual machines on open stack can be found &lt;a href=&quot;https://www.openstack.org/software/start/&quot;&gt;here&lt;/a&gt;.  We will be using Ubuntu 16.04 as the OS of both virtuall machines. Note, we need to associate a floating IP address to our public web server.</p>
<h2>Step 1: Install LAMP stack on Web Server</h2>
<p>Use ssh to login into the Web server. We will first install the LAMP stack manually. LAMP stack includes Linux, Apache, MySQL and PHP. It's considered by many as the platform of choice for development and deployment of web applications.</p>
<p>Note: you need to have a non-root user with <em>sudo</em> privileges to continue.</p>
<p>To install Apache, use the following command:</p>
<p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">$ sudo apt-get update</span><br><span class="line">$ sudo apt-get install apache2</span><br></pre></td></tr></table></figure></p>
<p>Then for MySQL, the command is very similar:</p>
<p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ sudo apt-get install mysql-server</span><br></pre></td></tr></table></figure></p>
<p>For PHP, we need some additional metapackages:</p>
<p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ sudo apt-get install php libapache2-mod-php php-mcrypt php-mysql</span><br></pre></td></tr></table></figure></p>
<p>Your server should restart the apache server; if not, use the following command:</p>
<p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ sudo /etc/init.d/apache2 restart</span><br></pre></td></tr></table></figure></p>
<p>You should now have the Ubuntu LAMP server works. You can check php works by running any php files in <code>/var/www/</code> directory.</p>
<h2>Step 2: Configure Apache on Web Server</h2>
<p>Before we test our apache, the first thing we need to do is to modify our firework to allow outside access to the default web ports. For a default setting, you should have a UFW firewall configured to restrict access to your server.</p>
<p>During installation, Apache registers itself with UFW to provide a few application profiles. We can use these profiles to simplify the process of enabling or disabling access to Apache through our firewall.</p>
<p>To check the ufw application profiles, use</p>
<p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ sudo ufw app list</span><br></pre></td></tr></table></figure></p>
<p>You should get an output like the following:</p>
<p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">Available applications:</span><br><span class="line">  Apache</span><br><span class="line">  Apache Full</span><br><span class="line">  Apache Secure</span><br><span class="line">  OpenSSH</span><br></pre></td></tr></table></figure></p>
<p>For our purposes, we will allow incoming traffic for the <strong>Apache Full</strong> profile by typing:</p>
<p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ sudo ufw allow &apos;Apache Full&apos;</span><br></pre></td></tr></table></figure></p>
<p>You can verify the change by:</p>
<p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ sudo ufw status</span><br></pre></td></tr></table></figure></p>
<p>The output should look like:</p>
<p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">Status: active</span><br><span class="line"></span><br><span class="line">To                         Action      From</span><br><span class="line">--                         ------      ----</span><br><span class="line">OpenSSH                    ALLOW       Anywhere                  </span><br><span class="line">Apache Full                ALLOW       Anywhere                  </span><br><span class="line">OpenSSH (v6)               ALLOW       Anywhere (v6)             </span><br><span class="line">Apache Full (v6)           ALLOW       Anywhere (v6)</span><br></pre></td></tr></table></figure></p>
<p>Now, hopefully you will have your Apache working.</p>
<h2>Step 3 Get the App repository and Configure PHP</h2>
<p>Use git clone to clone the repository into your front end server (Web Server).</p>
<p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ git clone https://github.com/Anirban2404/phpMySQLapp.git</span><br></pre></td></tr></table></figure></p>
<p>Move the directory to under <code>/var/www/html/</code> to enable php script. Use <code>tree</code> can clearly see the structure of the directory.</p>
<p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br></pre></td><td class="code"><pre><span class="line">ubuntu@mywebserver:/var/www/html$ tree</span><br><span class="line">.</span><br><span class="line">├── admin_area</span><br><span class="line">│   ├── insertbook.php</span><br><span class="line">│   ├── insert_books.php</span><br><span class="line">│   ├── insertmovie.php</span><br><span class="line">│   └── insert_movies.php</span><br><span class="line">├── books</span><br><span class="line">│   ├── functions</span><br><span class="line">│   │   ├── fetch.php</span><br><span class="line">│   │   ├── functions.php</span><br><span class="line">│   │   └── getbook.php</span><br><span class="line">│   ├── home.php</span><br><span class="line">│   ├── images</span><br><span class="line">│   │   └── background_image.jpg</span><br><span class="line">│   └── includes</span><br><span class="line">│       └── bookDatabase.php</span><br><span class="line">├── homePage.JPG</span><br><span class="line">├── index.php</span><br><span class="line">├── index.html</span><br><span class="line">├── movies</span><br><span class="line">│   ├── functions</span><br><span class="line">│   │   ├── fetch.php</span><br><span class="line">│   │   ├── functions.php</span><br><span class="line">│   │   └── getmovie.php</span><br><span class="line">│   ├── home.php</span><br><span class="line">│   ├── images</span><br><span class="line">│   │   └── background_image.jpg</span><br><span class="line">│   └── includes</span><br><span class="line">│       └── movieDatabase.php</span><br><span class="line">├── mySqlDB</span><br><span class="line">│   ├── bookDB.sql</span><br><span class="line">│   └── movieDB.sql</span><br><span class="line">├── README.md</span><br><span class="line">└── siteImages</span><br><span class="line">    ├── books.jpg</span><br><span class="line">    └── movies.jpg</span><br></pre></td></tr></table></figure></p>
<p>Note that <code>index.html</code> is the default page in the Apache server. You can either delete that file or configure PHP so that it will look into <code>index.php</code> to setup the front page.</p>
<p>To configure PHP, use <code>vim</code> or any texteditor like <code>nano</code>  to open <code>/etc/apache2/mods-enabled/dir.conf</code> as:</p>
<p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ sudo vim /etc/apache2/mods-enabled/dir.conf</span><br></pre></td></tr></table></figure></p>
<p>Change the order of the directory index into:</p>
<p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">DirectoryIndex index.php index.html index.cgi index.pl index.xhtml index.htm</span><br></pre></td></tr></table></figure></p>
<p>Now php will look for <code>index.php</code> before <code>index.html</code>.</p>
<h2>Step 4 Install MySQL and Configure it on Database Server</h2>
<p>SSH into our database server. As in the front end, we use apt-get to install MySQL.</p>
<p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ sudo apt-get install mysql-server</span><br></pre></td></tr></table></figure></p>
<p>When installing MySQL, it will prompt for password. Please remember it and we will use it later.</p>
<p>We also need to clone the repository of the Web App here. We need to import the 	database in the repository to our MySQL. So we do git clone again:</p>
<p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ git clone https://github.com/Anirban2404/phpMySQLapp.git</span><br></pre></td></tr></table></figure></p>
<p>Following the instruction on the repository README, we import the database into our MySQL database by</p>
<p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ mysql -u &lt;username&gt; -p &lt;databasename&gt; &lt; &lt;filename.sql&gt;</span><br></pre></td></tr></table></figure></p>
<p>Here, default username is root. Database names can be anything you like, but we are going to use them later. I chose 'bookstore' for my book database and 'movieDb' for my movie database. The files you need to import are in the 'mySqlDB' folder, as shown in the above tree. Argument -u is for username, -p means using password. This command will prompt you to enter your password for the database.</p>
<p>Now that we have import our database, we need to configure MySQL. First, use whatever texteditor you prefer to open the configuration file of MySQL. The file location may vary depend on different package. For this demonstration, the command is:</p>
<p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ sudo vim /etc/mysql/mysql.conf.d/mysqld.cnf</span><br></pre></td></tr></table></figure></p>
<p>In the configuration file, we need to bind our IP address to our database. Scroll down to find a line that looks like:</p>
<p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">bind-address		= xxx.xxx.xx.xx</span><br></pre></td></tr></table></figure></p>
<p>Replace the IP address with our database server's IP address. If there is a line starts with skip-networking, comment it out:</p>
<p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">#skip-networking</span><br></pre></td></tr></table></figure></p>
<p>Now save and exit the file. Restart the MySQL service:</p>
<p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ service mysql restart</span><br></pre></td></tr></table></figure></p>
<p>The final step is to grant the privilege of our user from other IP address. First Enter MySQL database by</p>
<p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ mysql -u root -p</span><br></pre></td></tr></table></figure></p>
<p>Replace root with your username if needed. In MySQL, type the following command:</p>
<p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">mysql&gt; GRANT ALL PRIVILEGES ON *.* TO &apos;USERNAME&apos;@&apos;%&apos; IDENTIFIED BY &apos;PASSWORD&apos; WITH GRANT OPTION;</span><br></pre></td></tr></table></figure></p>
<p>Here 'USERNAME' should be your username, 'PASSWORD' should be your password. This command will grant privilege to user from any IP address. You can check that privileges are granted by:</p>
<p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">SELECT * from information_schema.user_privileges;</span><br></pre></td></tr></table></figure></p>
<p>You should see your user at the bottom of the chart. Now your database server is ready for use.</p>
<h2>Step 5 Final Configuration on Web App</h2>
<p>A final modification is on our Web server. SSH into it as usual. Use text editor to open <code>/var/www/html/books/includes/bookDatabase.php</code> and <code>/var/www/html/movies/includes/movieDatabase.php</code>. You need to replace the IP address there with the database server's IP address. If your password is not default password, replace it as well.</p>
<p>After this final step, <strong>Congratulations!</strong> You should have manually deploy a cloud architecture!</p>
<p>To run this app, open a browser and enter your web server's public floating IP address. You should see a page like:</p>
<p>&lt;img src=&quot;images/Others/homePage.JPG&quot;&gt;</p>
<h2>Reference</h2>
<ol>
<li>http://howtoubuntu.org/how-to-install-lamp-on-ubuntu</li>
<li>https://stackoverflow.com/questions/8348506/grant-remote-access-of-mysql-database-from-any-ip-address</li>
<li>https://www.digitalocean.com/community/tutorials/how-to-install-the-apache-web-server-on-ubuntu-16-04</li>
</ol>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
  </section>

  
  <nav class="pagination">
    <span class="page-number current">1</span><a class="page-number" href="/page/2/">2</a><span class="space">&hellip;</span><a class="page-number" href="/page/4/">4</a><a class="extend next" rel="next" href="/page/2/"><i class="fa fa-angle-right"></i></a>
  </nav>



          </div>
          


          

        </div>
        
          
  
  <div class="sidebar-toggle">
    <div class="sidebar-toggle-line-wrap">
      <span class="sidebar-toggle-line sidebar-toggle-line-first"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-middle"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-last"></span>
    </div>
  </div>

  <aside id="sidebar" class="sidebar">
    
    <div class="sidebar-inner">

      

      

      <section class="site-overview-wrap sidebar-panel sidebar-panel-active">
        <div class="site-overview">
          <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
            
              <p class="site-author-name" itemprop="name">Ziqi Yang</p>
              <p class="site-description motion-element" itemprop="description">Welcome to my hub</p>
          </div>

          <nav class="site-state motion-element">

            
              <div class="site-state-item site-state-posts">
              
                <a href="/archives/">
              
                  <span class="site-state-item-count">33</span>
                  <span class="site-state-item-name">posts</span>
                </a>
              </div>
            

            
              
              
              <div class="site-state-item site-state-categories">
                <a href="/categories/index.html">
                  <span class="site-state-item-count">13</span>
                  <span class="site-state-item-name">categories</span>
                </a>
              </div>
            

            
              
              
              <div class="site-state-item site-state-tags">
                <a href="/tags/index.html">
                  <span class="site-state-item-count">13</span>
                  <span class="site-state-item-name">tags</span>
                </a>
              </div>
            

          </nav>

          

          

          
          

          
          

          

        </div>
      </section>

      

      

    </div>
  </aside>


        
      </div>
    </main>

    <footer id="footer" class="footer">
      <div class="footer-inner">
        <div class="copyright">&copy; <span itemprop="copyrightYear">2018</span>
  <span class="with-love">
    <i class="fa fa-user"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">Ziqi Yang</span>

  
</div>


  <div class="powered-by">Powered by <a class="theme-link" target="_blank" href="https://hexo.io">Hexo</a></div>



  <span class="post-meta-divider">|</span>



  <div class="theme-info">Theme &mdash; <a class="theme-link" target="_blank" href="https://github.com/iissnan/hexo-theme-next">NexT.Pisces</a> v5.1.4</div>




        







        
      </div>
    </footer>

    
      <div class="back-to-top">
        <i class="fa fa-arrow-up"></i>
        
      </div>
    

    

  </div>

  

<script type="text/javascript">
  if (Object.prototype.toString.call(window.Promise) !== '[object Function]') {
    window.Promise = null;
  }
</script>









  






  
  







  
  
    <script type="text/javascript" src="/lib/jquery/index.js?v=2.1.3"></script>
  

  
  
    <script type="text/javascript" src="/lib/fastclick/lib/fastclick.min.js?v=1.0.6"></script>
  

  
  
    <script type="text/javascript" src="/lib/jquery_lazyload/jquery.lazyload.js?v=1.9.7"></script>
  

  
  
    <script type="text/javascript" src="/lib/velocity/velocity.min.js?v=1.2.1"></script>
  

  
  
    <script type="text/javascript" src="/lib/velocity/velocity.ui.min.js?v=1.2.1"></script>
  

  
  
    <script type="text/javascript" src="/lib/fancybox/source/jquery.fancybox.pack.js?v=2.1.5"></script>
  

  
  
    <script type="text/javascript" src="/lib/three/three.min.js"></script>
  

  
  
    <script type="text/javascript" src="/lib/three/canvas_lines.min.js"></script>
  


  


  <script type="text/javascript" src="/js/src/utils.js?v=5.1.4"></script>

  <script type="text/javascript" src="/js/src/motion.js?v=5.1.4"></script>



  
  


  <script type="text/javascript" src="/js/src/affix.js?v=5.1.4"></script>

  <script type="text/javascript" src="/js/src/schemes/pisces.js?v=5.1.4"></script>



  

  


  <script type="text/javascript" src="/js/src/bootstrap.js?v=5.1.4"></script>



  


  




	





  





  












  





  

  

  

  
  

  
  
    <script type="text/x-mathjax-config">
      MathJax.Hub.Config({
        tex2jax: {
          inlineMath: [ ['$','$'], ["\\(","\\)"]  ],
          processEscapes: true,
          skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
        }
      });
    </script>

    <script type="text/x-mathjax-config">
      MathJax.Hub.Queue(function() {
        var all = MathJax.Hub.getAllJax(), i;
        for (i=0; i < all.length; i += 1) {
          all[i].SourceElement().parentNode.className += ' has-jax';
        }
      });
    </script>
    <script type="text/javascript" src="//cdn.bootcss.com/mathjax/2.7.1/latest.js?config=TeX-AMS-MML_HTMLorMML"></script>
  


  

  

</body>
</html>
