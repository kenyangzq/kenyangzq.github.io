<!DOCTYPE html>



  


<html class="theme-next pisces use-motion" lang="en">
<head>
  <meta charset="UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=edge" />
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"/>
<meta name="theme-color" content="#222">









<meta http-equiv="Cache-Control" content="no-transform" />
<meta http-equiv="Cache-Control" content="no-siteapp" />
















  
  
  <link href="/lib/fancybox/source/jquery.fancybox.css?v=2.1.5" rel="stylesheet" type="text/css" />







<link href="/lib/font-awesome/css/font-awesome.min.css?v=4.6.2" rel="stylesheet" type="text/css" />

<link href="/css/main.css?v=5.1.4" rel="stylesheet" type="text/css" />


  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png?v=5.1.4">


  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png?v=5.1.4">


  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png?v=5.1.4">


  <link rel="mask-icon" href="/images/logo.svg?v=5.1.4" color="#222">





  <meta name="keywords" content="Machine Learning,Deep Learning," />










<meta name="description" content="Basic Neural Network​    In last few months, I have taken 3 online courses on coursera and udemy about machine learning. Now I am going on a serious of deep learning course by lazy programmer . I do l">
<meta name="keywords" content="Machine Learning,Deep Learning">
<meta property="og:type" content="article">
<meta property="og:title" content="Neural Network Note 1">
<meta property="og:url" content="http://yoursite.com/2017/08/24/Neural-Network-Note-1/index.html">
<meta property="og:site_name" content="Runner">
<meta property="og:description" content="Basic Neural Network​    In last few months, I have taken 3 online courses on coursera and udemy about machine learning. Now I am going on a serious of deep learning course by lazy programmer . I do l">
<meta property="og:locale" content="en">
<meta property="og:updated_time" content="2017-08-25T03:38:19.000Z">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="Neural Network Note 1">
<meta name="twitter:description" content="Basic Neural Network​    In last few months, I have taken 3 online courses on coursera and udemy about machine learning. Now I am going on a serious of deep learning course by lazy programmer . I do l">



<script type="text/javascript" id="hexo.configurations">
  var NexT = window.NexT || {};
  var CONFIG = {
    root: '/',
    scheme: 'Pisces',
    version: '5.1.4',
    sidebar: {"position":"left","display":"post","offset":12,"b2t":false,"scrollpercent":false,"onmobile":false},
    fancybox: true,
    tabs: true,
    motion: {"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}},
    duoshuo: {
      userId: '0',
      author: 'Author'
    },
    algolia: {
      applicationID: '',
      apiKey: '',
      indexName: '',
      hits: {"per_page":10},
      labels: {"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}
    }
  };
</script>



  <link rel="canonical" href="http://yoursite.com/2017/08/24/Neural-Network-Note-1/"/>





  <title>Neural Network Note 1 | Runner</title>
  








</head>

<body itemscope itemtype="http://schema.org/WebPage" lang="en">

  
  
    
  

  <div class="container sidebar-position-left page-post-detail">
    <div class="headband"></div>

    <header id="header" class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-wrapper">
  <div class="site-meta ">
    

    <div class="custom-logo-site-title">
      <a href="/"  class="brand" rel="start">
        <span class="logo-line-before"><i></i></span>
        <span class="site-title">Runner</span>
        <span class="logo-line-after"><i></i></span>
      </a>
    </div>
      
        <p class="site-subtitle">Hacking to the gate</p>
      
  </div>

  <div class="site-nav-toggle">
    <button>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
    </button>
  </div>
</div>

<nav class="site-nav">
  

  
    <ul id="menu" class="menu">
      
        
        <li class="menu-item menu-item-home">
          <a href="/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-home"></i> <br />
            
            Home
          </a>
        </li>
      
        
        <li class="menu-item menu-item-archives">
          <a href="/archives/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-archive"></i> <br />
            
            Archives
          </a>
        </li>
      

      
    </ul>
  

  
</nav>



 </div>
    </header>

    <main id="main" class="main">
      <div class="main-inner">
        <div class="content-wrap">
          <div id="content" class="content">
            

  <div id="posts" class="posts-expand">
    

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2017/08/24/Neural-Network-Note-1/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Ziqi Yang">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Runner">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">Neural Network Note 1</h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Posted on</span>
              
              <time title="Post created" itemprop="dateCreated datePublished" datetime="2017-08-24T21:34:21-05:00">
                2017-08-24
              </time>
            

            

            
          </span>

          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        <h1 id="Basic-Neural-Network"><a href="#Basic-Neural-Network" class="headerlink" title="Basic Neural Network"></a>Basic Neural Network</h1><p>​    In last few months, I have taken 3 online courses on coursera and udemy about machine learning. Now I am going on a serious of deep learning course by <a href="https://lazyprogrammer.me/" target="_blank" rel="noopener">lazy programmer </a>. I do love this series a lot and I want to post some of my note on my blog. </p>
<h2 id="Forward-Propagation"><a href="#Forward-Propagation" class="headerlink" title="Forward Propagation"></a>Forward Propagation</h2><p>It’s quite a work to type the derivation and theory part in latex so I choose to just scratch the surface of them. </p>
<p>The first important function in the course is the <em>prediction</em> of a neural network using forward propagation. We create a 3 groups classification problem and predict the label use randomly initialized weight and bias. </p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np </span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt </span><br><span class="line"></span><br><span class="line">Nclass = <span class="number">500</span> </span><br><span class="line"></span><br><span class="line">X1 = np.random.randn(Nclass,<span class="number">2</span>) + np.array([<span class="number">0</span>,<span class="number">-2</span>])</span><br><span class="line">X2 = np.random.randn(Nclass,<span class="number">2</span>) + np.array([<span class="number">2</span>,<span class="number">2</span>])</span><br><span class="line">X3 = np.random.randn(Nclass,<span class="number">2</span>) + np.array([<span class="number">-2</span>,<span class="number">2</span>])</span><br><span class="line">X = np.vstack([X1, X2, X3])</span><br><span class="line"></span><br><span class="line">Y = np.array([<span class="number">0</span>]*Nclass + [<span class="number">1</span>]*Nclass + [<span class="number">2</span>]*Nclass)</span><br><span class="line"></span><br><span class="line">plt.scatter(X[:,<span class="number">0</span>], X[:,<span class="number">1</span>], c=Y, s = <span class="number">100</span>, alpha = <span class="number">.5</span>)</span><br><span class="line"><span class="comment"># plt.show()	</span></span><br><span class="line"></span><br><span class="line">D = <span class="number">2</span></span><br><span class="line">M = <span class="number">3</span></span><br><span class="line">K = <span class="number">3</span></span><br><span class="line"></span><br><span class="line">W1 = np.random.randn(D,M)</span><br><span class="line">b1 = np.random.randn(M)</span><br><span class="line">W2 = np.random.randn(M,K)</span><br><span class="line">b2 = np.random.randn(K)</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">forward</span><span class="params">(X,W1,b1,W2,b2)</span>:</span></span><br><span class="line">	Z = <span class="number">1</span> / (<span class="number">1</span> + np.exp(-X.dot(W1) - b1))</span><br><span class="line">	A = Z.dot(W2) + b2</span><br><span class="line">	expA = np.exp(A)</span><br><span class="line">	Y = expA / expA.sum(axis = <span class="number">1</span>, keepdims = <span class="keyword">True</span>)</span><br><span class="line">	<span class="keyword">return</span> Y</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">classification_rate</span><span class="params">(Y, P)</span>:</span></span><br><span class="line">	n_correct = <span class="number">0</span></span><br><span class="line">	n_total = <span class="number">0</span></span><br><span class="line">	<span class="keyword">for</span> i <span class="keyword">in</span> range(len(Y)):</span><br><span class="line">		n_total +=<span class="number">1</span> </span><br><span class="line">		<span class="keyword">if</span> Y[i] == P[i]:</span><br><span class="line">			n_correct += <span class="number">1</span></span><br><span class="line">	<span class="keyword">return</span> float(n_correct) / n_total</span><br><span class="line"></span><br><span class="line">P_Y_given_X = forward(X,W1,b1,W2,b2)</span><br><span class="line">P = np.argmax(P_Y_given_X, axis=<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">assert</span>(len(P) == len(Y))</span><br><span class="line"></span><br><span class="line">print(<span class="string">"Classification rate for randomly chosen weights:"</span>, classification_rate(Y,P))</span><br></pre></td></tr></table></figure>
<p>The code is pretty straightforward.</p>
<h2 id="Back-propagation"><a href="#Back-propagation" class="headerlink" title="Back propagation"></a>Back propagation</h2><p>The back propagation however, need some math derivation for the formula. </p>
<p>I really like the video “<em>The WRONG way to learn Backpropagation</em>“ in this course. People do not understand bp by just taking the difference between target and prediction and claim that multiplying this $\Delta$ with weight is somehow the derivative of the cost function. We find this by strict math derivation and observe the pattern then build this algorithm. The key is to expose the pattern yourself using gradient decent and substitute the repeating pattern. </p>
<h4 id="Some-Hardcore-Math"><a href="#Some-Hardcore-Math" class="headerlink" title="Some Hardcore Math"></a>Some Hardcore Math</h4><p>Suppose we are working on a multiclass classification problem with $K$ target classes.</p>
<p>Let’s say we have a cost function $L = \sum_n\sum_k t_k^n \log(y_k^n)$ where $n$ denotes the sampel number and $k$ is for all the class. This is the famous cross entropy function and I have also discussed it in my previous note <em>Beauty in Math</em>. </p>
<p>Suppose we have $D$ input features and 1 hidden layer with $M$ nodes. We use $W<em>{DM}$ and $V</em>{MK}$ to denote the weight between input layer and hidden layer and weights between hidden layer and output layer respectively. For simplicity, suppose there is no bias terms. And further assume that we are using sigmoid function as activation function on hidden layer and softmax function on output layer. </p>
<p>Now our goal is to derive $\frac{\partial L}{\partial V<em>{MK}}$ and $\frac{\partial L}{\partial W</em>{DM}}$. First apply chain rule<br>$$<br>\frac{\partial L}{\partial V_{mk}} = \sum<em>n \sum</em>{k’} t<em>{k’}^n \frac{1}{y</em>{k’}^n}\frac{\partial y<em>{k’}^n}{\partial V</em>{mk}}<br>$$<br>Note here $k’$ is not the same as $k$ and $V_{mk}$ denotes one entry in weight matrix $V$.</p>
<p>We know that<br>$$<br>y<em>{k’}^n = softmax(V</em>{K}^TZ) = \frac{\exp^{a_k}}{\sum_j \exp^{a_j}} \<br>a_k = V_K^T Z = \sum<em>m V</em>{mk} Z_m<br>$$<br>where $Z$ denote the output at the hidden layer. </p>
<p>If $k = k’$ , we have $\frac{\partial y_{k’}}{\partial a<em>k} = y</em>{k’}(1-y<em>k)$, and else $\frac{\partial y</em>{k’}}{\partial a<em>k} = -y</em>{k’}y<em>k$. So we can rewrite them using Kronecker Delta as<br>$$<br>\frac{\partial y</em>{k’}}{\partial a<em>k} = y</em>{k’}(\delta_{k’k} - y<em>k)<br>$$<br>Then<br>$$<br>\frac{\partial y</em>{k’}^n}{\partial V<em>{mk}} = \frac{\partial y</em>{k’}^n}{\partial a_{k}} \frac{\partial a<em>k}{\partial V</em>{mk}} =y<em>{k’}(\delta</em>{k’k} - y_k) Z<em>m<br>$$<br>So<br>$$<br>\begin{align}<br>\frac{\partial L}{\partial V</em>{mk}} &amp;= \sum<em>n \sum</em>{k’} t<em>{k’}^n \frac{1}{y</em>{k’}^n}y<em>{k’}^n(\delta</em>{k’k} - y_k^n) Z_m^n \<br>&amp;= \sum<em>n \sum</em>{k’} (t<em>{k’}^n \delta</em>{k’k} - t_{k’}^ny_k^n)Z_m^n \<br>&amp;= \sum_n (t<em>k^n - \sum</em>{k’} t_{k’}^ny_k^n )Z_m^n \<br>&amp;= \sum_n (t_k^n - y_k^n )Z_m^n<br>\end{align}<br>$$<br>since $\sum_k t_k \equiv 1$ as each sample belongs to only one class.</p>
<p>The derivation for $\frac{\partial L}{\partial W_{DM}}$ is just some additional work. Since we have<br>$$<br>Z<em>M = \frac{1}{1 + \exp^{-W</em>{MK}^TX}}<br>$$<br>we can easily derive that<br>$$<br>\begin{align}<br>\frac{\partial L}{\partial W_{dm}} &amp; = \sum_n (t_k^n - y_k^n ) \frac{\partial Z<em>m^n}{\partial W</em>{dm}} \<br>&amp; = \sum_n (t_k^n - y_k^n )Z_m^n (1-Z_m^n)X_d^n<br>\end{align}<br>$$<br>The pattern here is actually already visiable. If we have one more hidden layer with same activation function, all we need to do is just to replace $X_d^n$ with the hidden value and multiply by addition factors. Because of the recursive nature of derivatives, back propagation is able to handle any deep neural network. </p>
<p>When putting these into code, we definitely want to vectorize them. It’s pretty easy to make mistake as there are so many matrices to keep track of. One easy way I use to double check is to check the size of the matrix. Make sure their inner sizes match and the output size is the same as the target weight.</p>
<h4 id="Code"><a href="#Code" class="headerlink" title="Code"></a>Code</h4><p>In this code example, we keep working on the previous three groups problem.</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np </span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt </span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">forward</span><span class="params">(X,W1,b1,W2,b2)</span>:</span></span><br><span class="line">	Z = <span class="number">1</span> / (<span class="number">1</span> + np.exp(-X.dot(W1)-b1))</span><br><span class="line">	A = Z.dot(W2) + b2</span><br><span class="line">	expa = np.exp(A)</span><br><span class="line">	Y = expa / expa.sum(axis = <span class="number">1</span>, keepdims = <span class="keyword">True</span>)</span><br><span class="line">	<span class="keyword">return</span> Y, Z</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">classification_rate</span><span class="params">(Y,P)</span>:</span></span><br><span class="line">	n_correct = <span class="number">0</span></span><br><span class="line">	n_total = <span class="number">0</span></span><br><span class="line">	<span class="keyword">for</span> i <span class="keyword">in</span> range(len(Y)):</span><br><span class="line">		n_total += <span class="number">1</span></span><br><span class="line">		<span class="keyword">if</span> Y[i] == P[i]:</span><br><span class="line">			n_correct += <span class="number">1</span></span><br><span class="line"></span><br><span class="line">	<span class="keyword">return</span> float(n_correct) / n_total</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">cost</span><span class="params">(T, Y)</span>:</span></span><br><span class="line">	tot = T * np.log(Y)</span><br><span class="line">	<span class="keyword">return</span> tot.sum()</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">derivative_w2</span><span class="params">(Z, T, Y)</span>:</span></span><br><span class="line">	<span class="keyword">return</span> Z.T.dot(T - Y)</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">derivative_b2</span><span class="params">(T,Y)</span>:</span></span><br><span class="line">	<span class="keyword">return</span> (T-Y).sum(axis=<span class="number">0</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">derivative_w1</span><span class="params">(X, Z, T, Y, W2)</span>:</span></span><br><span class="line">	dZ = (T - Y).dot(W2.T) * Z * (<span class="number">1</span> - Z)</span><br><span class="line">	<span class="keyword">return</span> X.T.dot(dZ)</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">derivative_b1</span><span class="params">(T, Y, W2, Z)</span>:</span></span><br><span class="line">	<span class="keyword">return</span> ((T-Y).dot(W2.T) * Z * (<span class="number">1</span>-Z)).sum(axis=<span class="number">0</span>)</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">main</span><span class="params">()</span>:</span></span><br><span class="line">	Nclass = <span class="number">500</span></span><br><span class="line">	D = <span class="number">2</span> <span class="comment"># input</span></span><br><span class="line">	M = <span class="number">3</span> <span class="comment"># hidden layer</span></span><br><span class="line">	K = <span class="number">3</span> <span class="comment"># output</span></span><br><span class="line"></span><br><span class="line">	X1 = np.random.randn(Nclass,D) + np.array([<span class="number">0</span>,<span class="number">-2</span>])</span><br><span class="line">	X2 = np.random.randn(Nclass,D) + np.array([<span class="number">2</span>,<span class="number">2</span>])</span><br><span class="line">	X3 = np.random.randn(Nclass,D) + np.array([<span class="number">-2</span>,<span class="number">2</span>])</span><br><span class="line">	X = np.vstack([X1, X2, X3])</span><br><span class="line"></span><br><span class="line">	Y = np.array([<span class="number">0</span>]*Nclass + [<span class="number">1</span>]*Nclass + [<span class="number">2</span>] * Nclass)</span><br><span class="line">	N = len(Y)</span><br><span class="line"></span><br><span class="line">	T = np.zeros((N,K))</span><br><span class="line">	<span class="keyword">for</span> i <span class="keyword">in</span> range(N):</span><br><span class="line">		T[i,Y[i]] = <span class="number">1</span></span><br><span class="line"></span><br><span class="line">	<span class="comment"># plt.scatter(X[:,0], X[:,1], c=Y, s=100, alpha=.5)</span></span><br><span class="line">	<span class="comment"># plt.show()</span></span><br><span class="line"></span><br><span class="line">	W1 = np.random.randn(D, M)</span><br><span class="line">	b1 = np.random.randn(M)</span><br><span class="line">	W2 = np.random.randn(M, K)</span><br><span class="line">	b2 = np.random.randn(K)</span><br><span class="line"></span><br><span class="line">	learning_rate = <span class="number">10e-7</span></span><br><span class="line">	costs = []</span><br><span class="line">	<span class="keyword">for</span> epoch <span class="keyword">in</span> range(<span class="number">100000</span>):</span><br><span class="line">		output, hidden = forward(X,W1,b1,W2,b1)</span><br><span class="line">		<span class="keyword">if</span> epoch % <span class="number">100</span> == <span class="number">0</span>:</span><br><span class="line">			c = cost(T, output)</span><br><span class="line">			P = np.argmax(output, axis = <span class="number">1</span>)</span><br><span class="line">			r = classification_rate(Y,P)</span><br><span class="line">			print(<span class="string">"epoch"</span>, epoch, <span class="string">"cost"</span>, c, <span class="string">"classification rate:"</span>,r)</span><br><span class="line">			costs.append(c)</span><br><span class="line"></span><br><span class="line">		W2 += learning_rate *  derivative_w2(hidden, T, output)</span><br><span class="line">		b2 += learning_rate *  derivative_b2(T, output)</span><br><span class="line">		W1 += learning_rate *  derivative_w1(X, hidden, T, output, W2)</span><br><span class="line">		b1 += learning_rate *  derivative_b1(T, output, W2, hidden)</span><br><span class="line"></span><br><span class="line">	plt.plot(costs)</span><br><span class="line">	plt.show()</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">'__main__'</span>:</span><br><span class="line">	main()</span><br></pre></td></tr></table></figure>

      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      
        <div class="post-tags">
          
            <a href="/tags/Machine-Learning/" rel="tag"># Machine Learning</a>
          
            <a href="/tags/Deep-Learning/" rel="tag"># Deep Learning</a>
          
        </div>
      

      
      
      

      
        <div class="post-nav">
          <div class="post-nav-next post-nav-item">
            
              <a href="/2017/08/13/Research-Note-9/" rel="next" title="Research-Note-9">
                <i class="fa fa-chevron-left"></i> Research-Note-9
              </a>
            
          </div>

          <span class="post-nav-divider"></span>

          <div class="post-nav-prev post-nav-item">
            
              <a href="/2017/08/26/Research-New-Start/" rel="prev" title="Research-New-Start">
                Research-New-Start <i class="fa fa-chevron-right"></i>
              </a>
            
          </div>
        </div>
      

      
      
    </footer>
  </div>
  
  
  
  </article>



    <div class="post-spread">
      
    </div>
  </div>


          </div>
          


          

  



        </div>
        
          
  
  <div class="sidebar-toggle">
    <div class="sidebar-toggle-line-wrap">
      <span class="sidebar-toggle-line sidebar-toggle-line-first"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-middle"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-last"></span>
    </div>
  </div>

  <aside id="sidebar" class="sidebar">
    
    <div class="sidebar-inner">

      

      
        <ul class="sidebar-nav motion-element">
          <li class="sidebar-nav-toc sidebar-nav-active" data-target="post-toc-wrap">
            Table of Contents
          </li>
          <li class="sidebar-nav-overview" data-target="site-overview-wrap">
            Overview
          </li>
        </ul>
      

      <section class="site-overview-wrap sidebar-panel">
        <div class="site-overview">
          <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
            
              <p class="site-author-name" itemprop="name">Ziqi Yang</p>
              <p class="site-description motion-element" itemprop="description">Welcome to my hub</p>
          </div>

          <nav class="site-state motion-element">

            
              <div class="site-state-item site-state-posts">
              
                <a href="/archives/">
              
                  <span class="site-state-item-count">33</span>
                  <span class="site-state-item-name">posts</span>
                </a>
              </div>
            

            
              
              
              <div class="site-state-item site-state-categories">
                <a href="/categories/index.html">
                  <span class="site-state-item-count">13</span>
                  <span class="site-state-item-name">categories</span>
                </a>
              </div>
            

            
              
              
              <div class="site-state-item site-state-tags">
                <a href="/tags/index.html">
                  <span class="site-state-item-count">13</span>
                  <span class="site-state-item-name">tags</span>
                </a>
              </div>
            

          </nav>

          

          

          
          

          
          

          

        </div>
      </section>

      
      <!--noindex-->
        <section class="post-toc-wrap motion-element sidebar-panel sidebar-panel-active">
          <div class="post-toc">

            
              
            

            
              <div class="post-toc-content"><ol class="nav"><li class="nav-item nav-level-1"><a class="nav-link" href="#Basic-Neural-Network"><span class="nav-number">1.</span> <span class="nav-text">Basic Neural Network</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#Forward-Propagation"><span class="nav-number">1.1.</span> <span class="nav-text">Forward Propagation</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Back-propagation"><span class="nav-number">1.2.</span> <span class="nav-text">Back propagation</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#Some-Hardcore-Math"><span class="nav-number">1.2.0.1.</span> <span class="nav-text">Some Hardcore Math</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#Code"><span class="nav-number">1.2.0.2.</span> <span class="nav-text">Code</span></a></li></ol></li></ol></li></ol></li></ol></div>
            

          </div>
        </section>
      <!--/noindex-->
      

      

    </div>
  </aside>


        
      </div>
    </main>

    <footer id="footer" class="footer">
      <div class="footer-inner">
        <div class="copyright">&copy; <span itemprop="copyrightYear">2018</span>
  <span class="with-love">
    <i class="fa fa-user"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">Ziqi Yang</span>

  
</div>


  <div class="powered-by">Powered by <a class="theme-link" target="_blank" href="https://hexo.io">Hexo</a></div>



  <span class="post-meta-divider">|</span>



  <div class="theme-info">Theme &mdash; <a class="theme-link" target="_blank" href="https://github.com/iissnan/hexo-theme-next">NexT.Pisces</a> v5.1.4</div>




        







        
      </div>
    </footer>

    
      <div class="back-to-top">
        <i class="fa fa-arrow-up"></i>
        
      </div>
    

    

  </div>

  

<script type="text/javascript">
  if (Object.prototype.toString.call(window.Promise) !== '[object Function]') {
    window.Promise = null;
  }
</script>









  












  
  
    <script type="text/javascript" src="/lib/jquery/index.js?v=2.1.3"></script>
  

  
  
    <script type="text/javascript" src="/lib/fastclick/lib/fastclick.min.js?v=1.0.6"></script>
  

  
  
    <script type="text/javascript" src="/lib/jquery_lazyload/jquery.lazyload.js?v=1.9.7"></script>
  

  
  
    <script type="text/javascript" src="/lib/velocity/velocity.min.js?v=1.2.1"></script>
  

  
  
    <script type="text/javascript" src="/lib/velocity/velocity.ui.min.js?v=1.2.1"></script>
  

  
  
    <script type="text/javascript" src="/lib/fancybox/source/jquery.fancybox.pack.js?v=2.1.5"></script>
  


  


  <script type="text/javascript" src="/js/src/utils.js?v=5.1.4"></script>

  <script type="text/javascript" src="/js/src/motion.js?v=5.1.4"></script>



  
  


  <script type="text/javascript" src="/js/src/affix.js?v=5.1.4"></script>

  <script type="text/javascript" src="/js/src/schemes/pisces.js?v=5.1.4"></script>



  
  <script type="text/javascript" src="/js/src/scrollspy.js?v=5.1.4"></script>
<script type="text/javascript" src="/js/src/post-details.js?v=5.1.4"></script>



  


  <script type="text/javascript" src="/js/src/bootstrap.js?v=5.1.4"></script>



  


  




	





  





  












  





  

  

  

  
  

  

  

  

</body>
</html>
